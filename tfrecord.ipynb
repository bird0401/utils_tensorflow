{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfrecord.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7wy8lyDu63v5x2f+N6W2P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bird0401/utils_tensorflow/blob/main/tfrecord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_example(image,image_name,target,species):\n",
        "    feature = {\n",
        "        'image': _bytes_feature(image),\n",
        "        'image_name': _bytes_feature(image_name),\n",
        "        'target': _int64_feature(target),\n",
        "        'species': _int64_feature(species),\n",
        "      }\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    return example_proto.SerializeToString()"
      ],
      "metadata": {
        "id": "DurxtB5jZi25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_records(fold  = 0):\n",
        "    df = get_fold(fold)\n",
        "    tfr_filename = f'/tmp/{DATASET_NAME}/happywhale-2022-train-{fold}-{df.shape[0]}.tfrec'\n",
        "    with tf.io.TFRecordWriter(tfr_filename) as writer:\n",
        "        for i,row in df.iterrows():\n",
        "            image_id = row.image\n",
        "            target = row.individual_id\n",
        "            species = row.species\n",
        "            image_path = f\"../input/happy-whale-and-dolphin/train_images/{image_id}\"\n",
        "            image_encoded = tf.io.read_file(image_path)\n",
        "            image_name = str.encode(image_id)\n",
        "            example = serialize_example(image_encoded,image_name,target,species)\n",
        "            writer.write(example)"
      ],
      "metadata": {
        "id": "TBZ8jYjvZo41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_tf_records(fold  = 0):\n",
        "    df = test_df[test_df.split==fold]\n",
        "    tfr_filename = f'/tmp/{DATASET_NAME}/happywhale-2022-test-{fold}-{df.shape[0]}.tfrec'\n",
        "    with tf.io.TFRecordWriter(tfr_filename) as writer:\n",
        "        for i,row in df.iterrows():\n",
        "            image_id = row.image\n",
        "            target = -1\n",
        "            species = -1\n",
        "            image_path = f\"../input/happy-whale-and-dolphin/test_images/{image_id}\"\n",
        "            image_encoded = tf.io.read_file(image_path)\n",
        "            image_name = str.encode(image_id)\n",
        "            example = serialize_example(image_encoded,image_name,target,species)\n",
        "            writer.write(example)"
      ],
      "metadata": {
        "id": "KKMD7yr8Zsty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbTJPhCZfWTG"
      },
      "outputs": [],
      "source": [
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.image.resize(image,IMAGE_SIZE_)\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
        "        'target': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    label = example['target']\n",
        "    return image, label # returns a dataset of (image, label) pairs\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord)\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
        "    return dataset\n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ]
    }
  ]
}